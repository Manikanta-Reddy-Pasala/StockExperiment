# Automated Trading System

**High-performance automated trading system with triple ML models, dual strategies, and complete automation.**

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/)
[![Docker](https://img.shields.io/badge/Docker-20.10+-blue.svg)](https://www.docker.com/)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-15+-blue.svg)](https://www.postgresql.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

---

## üöÄ Quick Start

```bash
# 1. Start all services (Docker)
./run.sh dev

# 2. Access web interface
http://localhost:5001

# 3. Access admin dashboard (admin users only)
http://localhost:5001/admin

# 4. Check system status
./tools/check_all_schedulers.sh
```

**First run:** Initial pipeline takes ~30 minutes to populate data for 2,259 stocks.

**Subsequent runs:** Fully automated - no manual intervention needed!

---

## üìã Table of Contents

- [Features](#-features)
- [System Overview](#-system-overview)
- [Installation](#-installation)
- [Architecture](#-architecture)
- [Database Schema](#Ô∏è-database-schema)
- [API Endpoints](#-api-endpoints)
- [Automation](#-automation)
- [Machine Learning](#-machine-learning)
- [Configuration](#Ô∏è-configuration)
- [Usage Examples](#-usage-examples)
- [Monitoring](#-monitoring)
- [Troubleshooting](#-troubleshooting)
- [Performance](#-performance)
- [Documentation](#-documentation)
- [Contributing](#-contributing)

---

## ‚ú® Features

### ü§ñ Complete Automation
- **100% Automated Data Collection** - Runs daily at 9 PM after market close
- **Automated ML Training** - Trains 3 models daily at 10 PM with fresh data
- **Automated Stock Selection** - Generates daily top 50 picks √ó 3 models √ó 2 strategies
- **Automated Trading Execution** - Places orders at 9:20 AM with stop-loss/targets
- **Automated CSV Exports** - Daily backups for analysis and reporting
- **Self-Healing** - Saga pattern with retry logic (3 attempts, 60s delay)
- **Zero Manual Intervention** - Set it and forget it!

### üß† Triple Machine Learning Models
- **Traditional ML** (Random Forest + XGBoost ensemble)
  - Walk-forward cross-validation (5 splits)
  - 25-30 features (technical + fundamental)
  - Fast training (~1-2 minutes)
- **Raw LSTM** (Deep learning)
  - Per-symbol models with 60-day lookback
  - Predicts 14 days ahead
  - OHLCV sequence modeling
- **Kronos** (K-line tokenization)
  - Candlestick pattern recognition
  - Advanced technical analysis
  - Experimental cutting-edge model

### üìä Comprehensive Data Pipeline
- **6-Step Saga Pattern** - Symbols ‚Üí Stocks ‚Üí History ‚Üí Indicators ‚Üí Metrics ‚Üí Validation
- **2,259+ NSE Stocks** - All NSE-listed stocks with complete data
- **1-Year Historical Data** - 820K+ OHLCV records
- **Technical Indicators** - RSI, MACD, SMA, EMA, ATR, Bollinger Bands
- **Real-Time Updates** - Market data refresh during trading hours
- **Robust Error Handling** - Retry logic with exponential backoff

### üéØ Dual Strategy System
- **DEFAULT_RISK** (Conservative)
  - Large-cap stocks (>20,000 Cr market cap)
  - PE ratio 5-40, price ‚Çπ100-10,000
  - Target gain: 7%, Stop loss: 5%
  - Good liquidity requirements
- **HIGH_RISK** (Aggressive)
  - Small/Mid-cap stocks (1,000-20,000 Cr)
  - Broader criteria, lower score threshold
  - Target gain: 12%, Stop loss: 10%
  - Higher volatility tolerance

### üåê API & Interface
- **REST API** - Fast, cached endpoints with ML predictions
- **Admin Dashboard** - Manual task triggers with real-time monitoring
- **Web Interface** - Portfolio management and trading controls
- **Multi-Broker Support** - Unified broker service (Fyers, Zerodha, Simulator)
- **Real-Time Status** - Live task monitoring and logs
- **Auto-Trading** - Automated order placement with risk management

### üìà Analytics & Insights
- **6 Model Combinations** - 3 models √ó 2 strategies = comprehensive coverage
- **ML Prediction Scores** - 0-1 score for opportunity ranking
- **Confidence Levels** - Model confidence in predictions
- **Risk Scores** - Lower = safer investment
- **Performance Tracking** - Daily P&L snapshots
- **Ollama AI Enhancement** - Optional market intelligence layer

---

## üìä System Overview

### Daily Automation Schedule

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    AUTOMATED DAILY SCHEDULE                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

üåÖ Morning:
  06:00 AM ‚Üí Symbol Master Update (Monday Only)
             ‚Ä¢ Refresh NSE symbols from Fyers API
             ‚Ä¢ ~2,300 stocks
             ‚Ä¢ Duration: 1-2 minutes

  09:20 AM ‚Üí Auto-Trading Execution (Daily)
             ‚Ä¢ Check AI market sentiment
             ‚Ä¢ Apply weekly limits
             ‚Ä¢ Place orders with stop-loss/targets
             ‚Ä¢ Duration: 2-3 minutes

üåÜ Evening (Daily After Market Close):
  06:00 PM ‚Üí Performance Tracking
             ‚Ä¢ Update order performance
             ‚Ä¢ Create daily snapshots
             ‚Ä¢ Check stop-loss/targets
             ‚Ä¢ Close orders if needed
             ‚Ä¢ Duration: 1-2 minutes

  09:00 PM ‚Üí Data Pipeline (6-step saga)
             ‚Ä¢ Update all stock prices
             ‚Ä¢ Fetch 1-year historical OHLCV
             ‚Ä¢ Calculate technical indicators
             ‚Ä¢ Compute volatility metrics
             ‚Ä¢ Validate data quality
             ‚Ä¢ Duration: 20-30 minutes
             ‚Ä¢ Records: 2,259 stocks updated

  09:30 PM ‚Üí Fill Missing Data & Business Logic (Parallel)
             ‚Ä¢ Populate adj_close, liquidity
             ‚Ä¢ Calculate ATR, volatility
             ‚Ä¢ EPS, Book Value, PEG Ratio, ROA
             ‚Ä¢ Operating/Net/Profit Margins
             ‚Ä¢ Current/Quick Ratios, Debt to Equity
             ‚Ä¢ Duration: 5-10 minutes

  10:00 PM ‚Üí CSV Export & Data Validation (Parallel)
             ‚Ä¢ Export 4 CSV files (stocks, history, indicators, picks)
             ‚Ä¢ Validate data quality
             ‚Ä¢ Duration: 2-3 minutes

üåô Late Evening:
  10:00 PM ‚Üí ML Model Training (3 Models)
             ‚Ä¢ Model 1: Traditional ML (RF + XGBoost)
             ‚Ä¢ Model 2: Raw LSTM (Deep Learning)
             ‚Ä¢ Model 3: Kronos (K-line Tokenization)
             ‚Ä¢ Duration: 5-10 minutes total

  10:15 PM ‚Üí Daily Stock Selection (Triple Model √ó Dual Strategy)
             ‚Ä¢ Run for all 3 models
             ‚Ä¢ Apply both strategies (DEFAULT_RISK, HIGH_RISK)
             ‚Ä¢ Generate 6 combinations total
             ‚Ä¢ Optional: Ollama AI enhancement
             ‚Ä¢ Save to daily_suggested_stocks table
             ‚Ä¢ Duration: 3-5 minutes

  03:00 AM ‚Üí Cleanup Old Data (Sunday Only)
             ‚Ä¢ Remove snapshots > 90 days
             ‚Ä¢ Remove CSV exports > 30 days
             ‚Ä¢ Duration: < 1 minute

Total Daily Automation Time: ~45-60 minutes
Total Manual Intervention: ZERO! üéâ
```

### Architecture Diagram

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     SYSTEM ARCHITECTURE                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

External APIs:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Fyers API   ‚îÇ‚îÄ‚îÄ‚îê
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
                  ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ Zerodha API  ‚îÇ‚îÄ‚îÄ‚î§
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
                  ‚Üì
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ  Flask App     ‚îÇ ‚Üê HTTP Requests
         ‚îÇ  (Port 5001)   ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚Üì
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ  Dragonfly     ‚îÇ
         ‚îÇ  (Redis Cache) ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ    PostgreSQL DB (15 tables)‚îÇ
    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
    ‚îÇ  ‚îÇ stocks (2,259)       ‚îÇ   ‚îÇ
    ‚îÇ  ‚îÇ historical_data      ‚îÇ   ‚îÇ
    ‚îÇ  ‚îÇ tech_indicators      ‚îÇ   ‚îÇ
    ‚îÇ  ‚îÇ daily_suggested      ‚îÇ   ‚îÇ
    ‚îÇ  ‚îÇ pipeline_tracking    ‚îÇ   ‚îÇ
    ‚îÇ  ‚îÇ orders, trades       ‚îÇ   ‚îÇ
    ‚îÇ  ‚îÇ auto_trading_settings‚îÇ   ‚îÇ
    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚Üë
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ                           ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Data Scheduler‚îÇ      ‚îÇ ML Scheduler ‚îÇ
‚îÇ  (9 PM daily) ‚îÇ      ‚îÇ (10 PM daily)‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

ML Models Storage:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Traditional ML:            ‚îÇ
‚îÇ ml_models/                 ‚îÇ
‚îÇ ‚îú‚îÄ‚îÄ rf_price_model.pkl     ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ xgb_price_model.pkl    ‚îÇ
‚îÇ                            ‚îÇ
‚îÇ Raw LSTM:                  ‚îÇ
‚îÇ ml_models/raw_ohlcv_lstm/  ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ {symbol}/              ‚îÇ
‚îÇ     ‚îî‚îÄ‚îÄ lstm_model.h5      ‚îÇ
‚îÇ                            ‚îÇ
‚îÇ Kronos:                    ‚îÇ
‚îÇ ml_models/kronos/          ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ kronos_model.pkl       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

CSV Exports:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  /exports  ‚îÇ        ‚îÇ   /logs    ‚îÇ
‚îÇ (CSV files)‚îÇ        ‚îÇ (App logs) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üîß Installation

### Prerequisites

- **Operating System:** Linux, macOS, or Windows (WSL2)
- **Docker:** Version 20.10 or higher
- **Docker Compose:** Version 2.0 or higher
- **Python:** 3.10 or higher (for local scripts)
- **Git:** For cloning the repository
- **Fyers API Credentials:** Client ID and Access Token

### Step 1: Clone Repository

```bash
git clone https://github.com/yourusername/StockExperiment.git
cd StockExperiment
```

### Step 2: Configure Fyers API

Create `.env` file in root:

```bash
# Fyers API Credentials
FYERS_CLIENT_ID=your_client_id_here
FYERS_ACCESS_TOKEN=your_access_token_here

# Database Configuration (default - don't change unless needed)
DATABASE_URL=postgresql://trader:trader_password@database:5432/trading_system
POSTGRES_USER=trader
POSTGRES_PASSWORD=trader_password
POSTGRES_DB=trading_system

# Redis Configuration
REDIS_HOST=dragonfly
REDIS_PORT=6379

# Application Settings
FLASK_ENV=development
FLASK_DEBUG=1
LOG_LEVEL=INFO
```

### Step 3: Start Docker Services

```bash
# Development mode (with auto-reload)
./run.sh dev

# Production mode
./run.sh prod
```

### Step 4: Wait for Initial Setup

```bash
# Monitor initial pipeline (takes ~30 minutes)
docker compose logs -f trading_system

# Check when ready
./tools/check_all_schedulers.sh
```

### Step 5: Access Application

```bash
# Web Interface
http://localhost:5001

# Admin Dashboard
http://localhost:5001/admin

# API Documentation
http://localhost:5001/api/suggested-stocks/

# Database (PostgreSQL)
docker exec -it trading_system_db psql -U trader -d trading_system
```

---

## üèóÔ∏è Architecture

### Technology Stack

**Backend:**
- **Python 3.10+** - Core language
- **Flask 3.0** - Web framework
- **SQLAlchemy 2.0** - ORM for database
- **PostgreSQL 15** - Primary database (11 tables)
- **Dragonfly (Redis)** - Caching layer
- **Scikit-learn** - Random Forest models
- **XGBoost** - Gradient boosting
- **TensorFlow 2.16+** - LSTM models
- **Pandas/NumPy** - Data processing
- **Schedule** - Task scheduling

**Frontend:**
- **Bootstrap 5** - UI framework
- **Chart.js** - Data visualization
- **JavaScript ES6** - Client-side logic
- **Jinja2** - Template engine

**DevOps:**
- **Docker & Docker Compose** - 5 containers orchestration
- **Git** - Version control
- **GitHub Actions** - CI/CD (optional)

### Directory Structure

```
/StockExperiment
‚îú‚îÄ‚îÄ README.md                     # This file
‚îú‚îÄ‚îÄ CLAUDE.md                     # AI assistant instructions
‚îú‚îÄ‚îÄ .env                          # Environment variables (create this)
‚îú‚îÄ‚îÄ .gitignore                    # Git ignore rules
‚îú‚îÄ‚îÄ requirements.txt              # Python dependencies
‚îú‚îÄ‚îÄ Dockerfile                    # Docker image definition
‚îú‚îÄ‚îÄ docker-compose.yml            # Docker services config
‚îÇ
‚îú‚îÄ‚îÄ app.py                        # Flask application entry
‚îú‚îÄ‚îÄ run.py                        # Application launcher
‚îú‚îÄ‚îÄ run.sh                        # Docker startup script
‚îú‚îÄ‚îÄ config.py                     # Application configuration
‚îÇ
‚îú‚îÄ‚îÄ run_pipeline.py               # Data pipeline orchestrator
‚îú‚îÄ‚îÄ data_scheduler.py             # Data automation (9 PM)
‚îú‚îÄ‚îÄ scheduler.py                  # ML automation (10 PM)
‚îÇ
‚îú‚îÄ‚îÄ /src                          # Source code
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ /models                   # Database models (SQLAlchemy ORM)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ database.py           # DB connection, session management
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models.py             # Core tables (users, orders, trades)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ stock_models.py       # Stock, SymbolMaster models
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ historical_models.py  # HistoricalData, TechnicalIndicators
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ /services                 # Business logic
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ /data                 # Data pipeline services
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pipeline_saga.py  # 6-step data saga
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ suggested_stocks_saga.py  # 7-step stock selection
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ historical_data_service.py # Smart data fetching
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ fyers_symbol_service.py  # Symbol management
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ /brokers              # Broker integrations
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ /core
‚îÇ   ‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ unified_broker_service.py # Multi-broker abstraction
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ /ml                   # Machine learning
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ enhanced_stock_predictor.py # Traditional ML (RF + XGBoost)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ raw_lstm_prediction_service.py # Raw LSTM models
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ kronos_prediction_service.py # Kronos K-line model
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ training_service.py # Model training orchestration
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ /trading              # Trading services
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ auto_trading_service.py # Automated trading
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ order_performance_tracking_service.py # P&L tracking
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ /web                      # Flask routes & templates
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ app.py                # Flask app factory
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ admin_routes.py       # Admin dashboard routes
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ /routes               # API routes
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ suggested_stocks_routes.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ /templates            # HTML templates
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ base.html         # Base template
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ dashboard.html    # Main dashboard
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ /admin            # Admin templates
‚îÇ   ‚îÇ           ‚îî‚îÄ‚îÄ dashboard.html
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ /utils                    # Helper utilities
‚îÇ       ‚îú‚îÄ‚îÄ logger.py             # Logging setup
‚îÇ       ‚îî‚îÄ‚îÄ helpers.py            # Common utilities
‚îÇ
‚îú‚îÄ‚îÄ /config                       # Configuration files
‚îÇ   ‚îú‚îÄ‚îÄ stock_filters.yaml        # Stock screening criteria
‚îÇ   ‚îú‚îÄ‚îÄ database.yaml             # Database settings
‚îÇ   ‚îî‚îÄ‚îÄ broker_config.yaml        # Broker settings
‚îÇ
‚îú‚îÄ‚îÄ /ml_models                    # Trained ML models
‚îÇ   ‚îú‚îÄ‚îÄ rf_price_model.pkl        # Random Forest price model
‚îÇ   ‚îú‚îÄ‚îÄ xgb_price_model.pkl       # XGBoost price model
‚îÇ   ‚îú‚îÄ‚îÄ /raw_ohlcv_lstm           # Per-symbol LSTM models
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ {SYMBOL}/lstm_model.h5
‚îÇ   ‚îî‚îÄ‚îÄ /kronos                   # Kronos models
‚îÇ       ‚îî‚îÄ‚îÄ kronos_model.pkl
‚îÇ
‚îú‚îÄ‚îÄ /tools                        # Utility scripts
‚îÇ   ‚îú‚îÄ‚îÄ README.md                 # Tools documentation
‚îÇ   ‚îú‚îÄ‚îÄ train_ml_model.py         # Manual ML training
‚îÇ   ‚îú‚îÄ‚îÄ batch_train_lstm_top_stocks.py # LSTM training for large-caps
‚îÇ   ‚îú‚îÄ‚îÄ batch_train_lstm_small_mid_cap.py # LSTM for small/mid-caps
‚îÇ   ‚îú‚îÄ‚îÄ generate_kronos_predictions.py # Kronos predictions
‚îÇ   ‚îî‚îÄ‚îÄ check_all_schedulers.sh   # Complete system status
‚îÇ
‚îú‚îÄ‚îÄ /logs                         # Application logs
‚îÇ   ‚îú‚îÄ‚îÄ data_scheduler.log        # Data pipeline logs
‚îÇ   ‚îú‚îÄ‚îÄ scheduler.log             # ML scheduler logs
‚îÇ   ‚îî‚îÄ‚îÄ app.log                   # Flask app logs
‚îÇ
‚îî‚îÄ‚îÄ /exports                      # CSV exports (daily)
    ‚îú‚îÄ‚îÄ stocks_YYYY-MM-DD.csv
    ‚îú‚îÄ‚îÄ historical_30d_YYYY-MM-DD.csv
    ‚îú‚îÄ‚îÄ technical_indicators_YYYY-MM-DD.csv
    ‚îî‚îÄ‚îÄ suggested_stocks_YYYY-MM-DD.csv
```

### Docker Services

```yaml
services:
  database:
    image: postgres:15
    container_name: trading_system_db
    ports: ["5432:5432"]
    volumes:
      - postgres_data:/var/lib/postgresql/data
    environment:
      POSTGRES_USER: trader
      POSTGRES_PASSWORD: trader_password
      POSTGRES_DB: trading_system

  dragonfly:
    image: docker.dragonflydb.io/dragonflydb/dragonfly
    container_name: trading_system_redis
    ports: ["6379:6379"]
    volumes:
      - dragonfly_data:/data

  trading_system:
    build: .
    container_name: trading_system_app
    ports: ["5001:5001"]
    depends_on: [database, dragonfly]
    volumes:
      - .:/app
      - ./logs:/app/logs
      - ./exports:/app/exports
      - ./ml_models:/app/ml_models
    environment:
      DATABASE_URL: postgresql://trader:trader_password@database:5432/trading_system
      REDIS_HOST: dragonfly

  data_scheduler:
    build: .
    container_name: trading_system_data_scheduler
    command: python data_scheduler.py
    depends_on: [database, dragonfly]
    volumes:
      - .:/app
      - ./logs:/app/logs
      - ./exports:/app/exports

  ml_scheduler:
    build: .
    container_name: trading_system_ml_scheduler
    command: python scheduler.py
    depends_on: [database, dragonfly]
    volumes:
      - .:/app
      - ./logs:/app/logs
      - ./ml_models:/app/ml_models
```

---

## üóÑÔ∏è Database Schema

### Table Overview (11+ Tables)

| Table | Records | Description |
|-------|---------|-------------|
| **stocks** | 2,259 | Current prices, fundamentals, ratios |
| **historical_data** | ~820,000 | 1-year OHLCV data |
| **technical_indicators** | ~820,000 | RSI, MACD, SMA, EMA, ATR |
| **daily_suggested_stocks** | Growing | Daily picks (3 models √ó 2 strategies) |
| **pipeline_tracking** | Variable | Pipeline saga status |
| **symbol_master** | ~2,259 | Complete NSE symbol list |
| **users** | Variable | User accounts |
| **strategies** | Variable | Trading strategies |
| **orders** | Variable | Order history with model/strategy |
| **trades** | Variable | Executed trades |
| **positions** | Variable | Current positions |
| **broker_configurations** | Variable | API credentials |
| **auto_trading_settings** | Variable | Per-user trading preferences |

### Core Tables Schema

#### `stocks` Table
```sql
CREATE TABLE stocks (
    id SERIAL PRIMARY KEY,
    symbol VARCHAR(50) UNIQUE NOT NULL,
    stock_name VARCHAR(200),

    -- Price & Market Data
    current_price DOUBLE PRECISION,
    market_cap DOUBLE PRECISION,
    volume BIGINT,
    avg_volume_30d BIGINT,

    -- Fundamental Ratios
    pe_ratio DOUBLE PRECISION,
    pb_ratio DOUBLE PRECISION,
    roe DOUBLE PRECISION,
    eps DOUBLE PRECISION,
    beta DOUBLE PRECISION,
    debt_to_equity DOUBLE PRECISION,

    -- Growth & Profitability
    revenue_growth DOUBLE PRECISION,
    earnings_growth DOUBLE PRECISION,
    operating_margin DOUBLE PRECISION,
    net_margin DOUBLE PRECISION,
    profit_margin DOUBLE PRECISION,

    -- Valuation
    book_value DOUBLE PRECISION,
    peg_ratio DOUBLE PRECISION,
    roa DOUBLE PRECISION,

    -- Liquidity
    current_ratio DOUBLE PRECISION,
    quick_ratio DOUBLE PRECISION,

    -- Volatility
    historical_volatility_1y DOUBLE PRECISION,
    atr_14 DOUBLE PRECISION,

    -- Metadata
    sector VARCHAR(100),
    industry VARCHAR(100),
    market_cap_category VARCHAR(20),
    data_source VARCHAR(50), -- 'real' or 'estimated_enhanced'
    last_updated TIMESTAMP,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

#### `daily_suggested_stocks` Table (Enhanced)
```sql
CREATE TABLE daily_suggested_stocks (
    id SERIAL PRIMARY KEY,
    date DATE NOT NULL,
    symbol VARCHAR(50) NOT NULL,
    stock_name VARCHAR(200),
    current_price DOUBLE PRECISION,
    market_cap DOUBLE PRECISION,

    -- Model & Strategy
    model_type VARCHAR(50),  -- 'traditional', 'raw_lstm', 'kronos'
    strategy VARCHAR(50) NOT NULL, -- 'default_risk', 'high_risk'
    selection_score DOUBLE PRECISION,
    rank INTEGER,

    -- ML Predictions
    ml_prediction_score DOUBLE PRECISION,  -- 0-1 (higher = better)
    ml_price_target DOUBLE PRECISION,      -- Predicted price
    ml_confidence DOUBLE PRECISION,        -- Model confidence 0-1
    ml_risk_score DOUBLE PRECISION,        -- Risk score 0-1 (lower = safer)

    -- Technical Indicators (snapshot)
    rsi_14 DOUBLE PRECISION,
    macd DOUBLE PRECISION,
    sma_50 DOUBLE PRECISION,
    sma_200 DOUBLE PRECISION,

    -- Fundamental Metrics (snapshot)
    pe_ratio DOUBLE PRECISION,
    pb_ratio DOUBLE PRECISION,
    roe DOUBLE PRECISION,
    eps DOUBLE PRECISION,
    beta DOUBLE PRECISION,

    -- Growth & Profitability
    revenue_growth DOUBLE PRECISION,
    earnings_growth DOUBLE PRECISION,
    operating_margin DOUBLE PRECISION,

    -- Trading Signals
    target_price DOUBLE PRECISION,
    stop_loss DOUBLE PRECISION,
    recommendation VARCHAR(20),
    reason TEXT,

    -- Metadata
    sector VARCHAR(100),
    market_cap_category VARCHAR(20),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,

    UNIQUE(date, symbol, strategy, model_type)  -- Allows upsert
);
CREATE INDEX idx_daily_suggested_date ON daily_suggested_stocks(date DESC);
CREATE INDEX idx_daily_suggested_ml_score ON daily_suggested_stocks(ml_prediction_score DESC);
CREATE INDEX idx_daily_suggested_model ON daily_suggested_stocks(model_type);
```

#### `pipeline_tracking` Table
```sql
CREATE TABLE pipeline_tracking (
    id SERIAL PRIMARY KEY,
    pipeline_id VARCHAR(100) UNIQUE NOT NULL,
    step VARCHAR(50) NOT NULL,
    status VARCHAR(50) NOT NULL, -- 'pending', 'in_progress', 'completed', 'failed', 'retrying'
    started_at TIMESTAMP,
    completed_at TIMESTAMP,
    retry_count INTEGER DEFAULT 0,
    max_retries INTEGER DEFAULT 3,
    error_message TEXT,
    records_processed INTEGER,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

---

## üåê API Endpoints

### Main Endpoint: Suggested Stocks

```http
GET /api/suggested-stocks/
```

**Query Parameters:**
- `strategy` - Trading strategy: `default_risk`, `high_risk` (default: `default_risk`)
- `model_type` - ML model: `traditional`, `raw_lstm`, `kronos` (optional, returns all if not specified)
- `limit` - Number of stocks to return (default: `50`, max: `100`)
- `sector` - Filter by sector (optional)
- `search` - Search by symbol or name (optional)
- `sort_by` - Sort field: `ml_prediction_score`, `market_cap`, `pe_ratio` (default: `ml_prediction_score`)
- `order` - Sort order: `asc`, `desc` (default: `desc`)

**Example Request:**
```bash
curl "http://localhost:5001/api/suggested-stocks/?strategy=default_risk&model_type=traditional&limit=10"
```

**Example Response:**
```json
{
  "success": true,
  "count": 10,
  "strategy": "default_risk",
  "model_type": "traditional",
  "generated_at": "2025-10-14T22:15:00",
  "stocks": [
    {
      "symbol": "RELIANCE",
      "stock_name": "Reliance Industries Ltd",
      "rank": 1,
      "current_price": 2450.50,
      "market_cap": 16500000.0,
      "sector": "Energy",
      "model_type": "traditional",

      "ml_prediction_score": 0.78,
      "ml_price_target": 2650.20,
      "ml_confidence": 0.85,
      "ml_risk_score": 0.12,

      "technical_indicators": {
        "rsi_14": 58.5,
        "macd": 12.3,
        "sma_50": 2400.0,
        "sma_200": 2300.0
      },

      "fundamentals": {
        "pe_ratio": 24.5,
        "pb_ratio": 2.8,
        "roe": 12.5,
        "eps": 100.5,
        "beta": 1.15,
        "revenue_growth": 8.5,
        "earnings_growth": 10.2,
        "operating_margin": 15.3
      },

      "trading_signals": {
        "target_price": 2625.0,
        "stop_loss": 2328.0,
        "recommendation": "BUY"
      }
    }
  ]
}
```

### Admin Dashboard Endpoints

#### Get System Status
```http
GET /admin/system/status
```

**Response:**
```json
{
  "success": true,
  "status": {
    "stocks": {
      "total": 2259,
      "with_price": 2250,
      "with_market_cap": 2240,
      "last_updated": "2025-10-14T21:30:00"
    },
    "historical_data": {
      "symbols": 2259,
      "records": 820574,
      "latest_date": "2025-10-14"
    },
    "ml_models": {
      "traditional": "trained",
      "raw_lstm": "84 symbols trained",
      "kronos": "trained"
    },
    "daily_snapshots": {
      "total": 15000,
      "unique_dates": 90,
      "latest_date": "2025-10-14",
      "model_combinations": 6
    }
  }
}
```

#### Trigger Tasks
```http
POST /admin/trigger/pipeline           # Run data pipeline
POST /admin/trigger/fill-data          # Fill missing data
POST /admin/trigger/business-logic     # Calculate metrics
POST /admin/trigger/ml-training        # Train all ML models
POST /admin/trigger/csv-export         # Export CSV files
POST /admin/trigger/all                # Run all tasks sequentially
```

---

## ü§ñ Automation

### Data Scheduler (`data_scheduler.py`)

**Schedule:**
- Symbol Master: Monday 6:00 AM
- Data Pipeline: Daily 9:00 PM
- Fill Data: Daily 9:30 PM (parallel)
- Business Logic: Daily 9:30 PM (parallel)
- CSV Export: Daily 10:00 PM (parallel)
- Data Validation: Daily 10:00 PM (parallel)

### ML Scheduler (`scheduler.py`)

**Schedule:**
- Auto-Trading: Daily 9:20 AM (5 min after market opens)
- Performance Tracking: Daily 6:00 PM (after market close)
- ML Training (3 models): Daily 10:00 PM
- Daily Snapshot: Daily 10:15 PM (6 combinations)
- Cleanup: Sunday 3:00 AM

### Manual Task Execution

**Via Admin Dashboard:**
```
http://localhost:5001/admin
‚Üí Click task buttons (Pipeline, ML Training, etc.)
‚Üí Monitor progress in real-time
‚Üí Retry failed steps
```

**Via Command Line:**
```bash
# Run data pipeline
python3 run_pipeline.py

# Train ML models
python3 tools/train_ml_model.py

# Train LSTM models
python3 tools/batch_train_lstm_top_stocks.py
python3 tools/batch_train_lstm_small_mid_cap.py

# Generate Kronos predictions
python3 tools/generate_kronos_predictions.py

# Fill missing data
python3 fill_data_sql.py
python3 fix_business_logic.py
```

---

## üß† Machine Learning

### Triple Model Architecture

#### 1. Traditional ML (Enhanced)
- **Algorithms:** Random Forest + XGBoost ensemble
- **Features:** 25-30 (technical + fundamental + chaos features)
- **Training:** Walk-forward cross-validation (5 splits)
- **Output:** Price predictions, risk assessment
- **Performance:** R¬≤ 0.15-0.35 (good for stocks)
- **Training Time:** 1-2 minutes

#### 2. Raw LSTM (Deep Learning)
- **Architecture:** LSTM neural networks
- **Input:** 60-day OHLCV sequences
- **Prediction:** 14 days ahead
- **Training:** Per-symbol models
- **Coverage:** Top liquid stocks
- **Training Time:** 5-10 minutes per batch

#### 3. Kronos (K-line Tokenization)
- **Approach:** Candlestick pattern recognition
- **Features:** K-line tokens, technical patterns
- **Innovation:** Experimental cutting-edge model
- **Coverage:** All stocks
- **Training Time:** 2-3 minutes

### Dual Strategy System

#### DEFAULT_RISK (Conservative)
```yaml
target_market_cap: "> 20,000 Cr"
pe_ratio: "5-40"
price_range: "‚Çπ100-10,000"
liquidity: "High"
target_gain: "7%"
stop_loss: "5%"
typical_stocks: "RELIANCE, TCS, HDFC, INFY"
```

#### HIGH_RISK (Aggressive)
```yaml
target_market_cap: "1,000-20,000 Cr"
pe_ratio: "Broader range"
price_range: "Flexible"
liquidity: "Medium"
target_gain: "12%"
stop_loss: "10%"
typical_stocks: "Mid/Small-cap growth stocks"
```

### Model Performance Metrics

**Total Combinations:** 6 (3 models √ó 2 strategies)

Each combination provides:
- `ml_prediction_score` (0-1): Higher = better opportunity
- `ml_price_target`: Expected price
- `ml_confidence` (0-1): Model confidence
- `ml_risk_score` (0-1): Lower = safer

### Feature Engineering

**Technical Features:**
- Price momentum, volume patterns
- RSI, MACD, Bollinger Bands
- SMA/EMA crossovers
- ATR volatility

**Fundamental Features:**
- PE, PB, ROE, ROA ratios
- Growth metrics (revenue, earnings)
- Profitability margins
- Liquidity ratios

**Engineered Features:**
- Chaos features (fractal dimension)
- Market regime indicators
- Sector relative strength
- Sentiment scores (optional)

---

## ‚öôÔ∏è Configuration

### Environment Variables (`.env`)

```bash
# Fyers API (Required)
FYERS_CLIENT_ID=your_fyers_client_id
FYERS_ACCESS_TOKEN=your_fyers_access_token

# Database (Default - don't change unless needed)
DATABASE_URL=postgresql://trader:trader_password@database:5432/trading_system
POSTGRES_USER=trader
POSTGRES_PASSWORD=trader_password
POSTGRES_DB=trading_system

# Redis
REDIS_HOST=dragonfly
REDIS_PORT=6379

# Flask
FLASK_ENV=development
FLASK_DEBUG=1
SECRET_KEY=your_secret_key_here

# Logging
LOG_LEVEL=INFO

# Screening Parameters (Optional)
SCREENING_QUOTES_RATE_LIMIT_DELAY=0.2
VOLATILITY_MAX_WORKERS=5
VOLATILITY_MAX_STOCKS=500
```

### Stock Filters (`config/stock_filters.yaml`)

```yaml
stage_1_filters:  # Market data screening
  tradeability:
    minimum_price: 50.0
    maximum_price: 10000.0
    minimum_daily_volume: 50000
    minimum_daily_turnover_inr: 50000000

stage_2_filters:  # Business logic screening
  filtering_thresholds:
    minimum_total_score: 25
  fundamental_ratios:
    max_pe_ratio: 50.0
    min_roe: 5.0
    max_debt_equity: 2.0
```

---

## üíº Usage Examples

### Example 1: Get Top Conservative Picks (Traditional ML)

```bash
curl "http://localhost:5001/api/suggested-stocks/?strategy=default_risk&model_type=traditional&limit=10"
```

### Example 2: Get Aggressive LSTM Picks

```bash
curl "http://localhost:5001/api/suggested-stocks/?strategy=high_risk&model_type=raw_lstm&limit=20"
```

### Example 3: Get All Kronos Predictions

```bash
curl "http://localhost:5001/api/suggested-stocks/?model_type=kronos&limit=50"
```

### Example 4: Query Database for Model Comparison

```sql
-- Connect to database
docker exec -it trading_system_db psql -U trader -d trading_system

-- Compare model performance
SELECT
    model_type,
    strategy,
    COUNT(*) as stocks,
    AVG(ml_prediction_score) as avg_score,
    AVG(ml_confidence) as avg_confidence
FROM daily_suggested_stocks
WHERE date = CURRENT_DATE
GROUP BY model_type, strategy
ORDER BY avg_score DESC;
```

---

## üìä Monitoring

### System Status

```bash
# Complete system status
./tools/check_all_schedulers.sh

# Docker containers
docker compose ps

# View logs (real-time)
docker compose logs -f
docker compose logs -f data_scheduler
docker compose logs -f ml_scheduler
docker compose logs -f trading_system
```

### Database Queries

```sql
-- Model coverage
SELECT
    model_type,
    COUNT(DISTINCT symbol) as unique_stocks,
    COUNT(*) as total_records
FROM daily_suggested_stocks
WHERE date = CURRENT_DATE
GROUP BY model_type;

-- Today's top picks across all models
SELECT
    symbol,
    stock_name,
    model_type,
    strategy,
    ml_prediction_score,
    ml_price_target,
    rank
FROM daily_suggested_stocks
WHERE date = CURRENT_DATE
ORDER BY ml_prediction_score DESC
LIMIT 20;

-- Pipeline status
SELECT * FROM pipeline_tracking
ORDER BY updated_at DESC
LIMIT 10;
```

---

## üîß Troubleshooting

### Common Issues

#### Pipeline Fails at HISTORICAL_DATA
```bash
# Rate limiting issue - increase delay
export SCREENING_QUOTES_RATE_LIMIT_DELAY=0.5

# Reduce parallel workers
export VOLATILITY_MAX_WORKERS=3

# Restart pipeline
python3 run_pipeline.py
```

#### ML Training Fails
```bash
# Check data availability
docker exec -it trading_system_db psql -U trader -d trading_system -c "SELECT COUNT(*) FROM historical_data;"

# Check disk space for models
df -h ml_models/

# Manual training
python3 tools/train_ml_model.py
```

#### Scheduler Not Running
```bash
# Check process
docker compose ps

# Restart schedulers
docker compose restart ml_scheduler data_scheduler

# Check logs
docker compose logs ml_scheduler | tail -50
```

---

## üìà Performance

### Metrics

- **Data Pipeline:** 20-30 minutes (2,259 stocks)
- **Traditional ML Training:** 1-2 minutes
- **LSTM Training:** 5-10 minutes (batch)
- **Kronos Training:** 2-3 minutes
- **Daily Snapshot:** 3-5 minutes (6 combinations)
- **API Response:** < 100ms (with cache)
- **Database Size:** ~1.6M records, ~500MB
- **Memory Usage:** ~500MB (Flask), ~1GB (PostgreSQL)

### Optimization Tips

1. **Saga Pattern:** Automatic retry prevents failures
2. **Parallel Processing:** Data tasks run in parallel
3. **Model Caching:** Models loaded once, cached in memory
4. **Database Indexes:** Optimized for common queries
5. **Redis Caching:** API responses cached

---

## üìö Documentation

| Document | Description |
|----------|-------------|
| **[README.md](README.md)** | This file - comprehensive overview |
| **[CLAUDE.md](CLAUDE.md)** | AI assistant instructions & codebase guide |
| **[AUTOMATION.md](docs/AUTOMATION.md)** | Complete automation guide |
| **[ML_GUIDE.md](docs/ML_GUIDE.md)** | Machine learning models documentation |
| **[STRUCTURE.md](docs/STRUCTURE.md)** | Project structure & data flow |
| **[tools/README.md](tools/README.md)** | Utility scripts documentation |

---

## ü§ù Contributing

### Development Setup

```bash
# Clone repository
git clone https://github.com/yourusername/StockExperiment.git
cd StockExperiment

# Create virtual environment
python3 -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Start development server
./run.sh dev
```

### Code Style

- **Python:** PEP 8, type hints preferred
- **SQL:** Uppercase keywords, snake_case tables
- **Saga Pattern:** Use for multi-step operations
- **Sessions:** Always use context managers
- **Models:** Lazy loading with caching

---

## üìÑ License

MIT License - See [LICENSE](LICENSE) file for details.

---

## üéâ Summary

‚úÖ **100% Automated** - Data collection, ML training, stock selection, trading execution
‚úÖ **Triple ML Models** - Traditional (RF+XGBoost), Raw LSTM, Kronos
‚úÖ **Dual Strategies** - Conservative (DEFAULT_RISK) and Aggressive (HIGH_RISK)
‚úÖ **6 Combinations Daily** - 3 models √ó 2 strategies = comprehensive coverage
‚úÖ **2,259+ NSE Stocks** - Complete fundamental and technical data
‚úÖ **Saga Pattern** - Reliable multi-step operations with retry logic
‚úÖ **Auto-Trading** - Automated order placement with risk management
‚úÖ **Performance Tracking** - Daily P&L snapshots and order monitoring
‚úÖ **Multi-Broker Support** - Unified service for Fyers, Zerodha, Simulator
‚úÖ **Production-Ready** - Docker, logging, error handling, monitoring

**Zero manual intervention required!** üöÄ

---

## üìû Support

### Getting Help

1. Check documentation in `/docs` folder
2. Review logs: `docker compose logs -f`
3. Check system status: `./tools/check_all_schedulers.sh`
4. Search issues on GitHub
5. Create new issue with logs and details

### Common Commands

```bash
# Start system
./run.sh dev

# Stop system
docker compose down

# Restart services
docker compose restart data_scheduler ml_scheduler trading_system

# View logs
docker compose logs -f [service_name]

# Check status
./tools/check_all_schedulers.sh

# Manual tasks
python3 run_pipeline.py
python3 tools/train_ml_model.py

# Database access
docker exec -it trading_system_db psql -U trader -d trading_system
```

---

**Built with ‚ù§Ô∏è for automated stock trading and analysis**

Last Updated: October 14, 2025